{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy import stats\n",
    "import glob\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('../../capstone_project_1/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rate Data\n",
    "df = pd.read_csv(path + 'ml-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate_NFL</th>\n",
       "      <th>Y/A_NFL</th>\n",
       "      <th>win_pct</th>\n",
       "      <th>AY/A_College</th>\n",
       "      <th>Att_College</th>\n",
       "      <th>Cmp_College</th>\n",
       "      <th>G_College</th>\n",
       "      <th>Int_College</th>\n",
       "      <th>Pct</th>\n",
       "      <th>Rate_College</th>\n",
       "      <th>TD_College</th>\n",
       "      <th>Y/A_College</th>\n",
       "      <th>Yds_College</th>\n",
       "      <th>above_nfl_ypa</th>\n",
       "      <th>above_nfl_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A.J. Feeley</td>\n",
       "      <td>66.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.6</td>\n",
       "      <td>259</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>52.5</td>\n",
       "      <td>129.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>97.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9.6</td>\n",
       "      <td>978</td>\n",
       "      <td>656</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>67.1</td>\n",
       "      <td>163.3</td>\n",
       "      <td>74</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>77.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>8.1</td>\n",
       "      <td>560</td>\n",
       "      <td>320</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>57.2</td>\n",
       "      <td>139.7</td>\n",
       "      <td>32</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>102.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>8.6</td>\n",
       "      <td>665</td>\n",
       "      <td>424</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>63.8</td>\n",
       "      <td>150.4</td>\n",
       "      <td>43</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Akili Smith</td>\n",
       "      <td>54.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.8</td>\n",
       "      <td>571</td>\n",
       "      <td>323</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>56.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>45</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Troy Smith</td>\n",
       "      <td>77.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.7</td>\n",
       "      <td>548</td>\n",
       "      <td>352</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>64.1</td>\n",
       "      <td>162.3</td>\n",
       "      <td>46</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyler Palko</td>\n",
       "      <td>59.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1072</td>\n",
       "      <td>643</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>60.4</td>\n",
       "      <td>141.7</td>\n",
       "      <td>66</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyrod Taylor</td>\n",
       "      <td>92.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>9.6</td>\n",
       "      <td>558</td>\n",
       "      <td>324</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>57.8</td>\n",
       "      <td>152.1</td>\n",
       "      <td>37</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vince Young</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>8.0</td>\n",
       "      <td>575</td>\n",
       "      <td>360</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>62.2</td>\n",
       "      <td>146.2</td>\n",
       "      <td>38</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4885</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zach Mettenberger</td>\n",
       "      <td>75.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>648</td>\n",
       "      <td>399</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>61.8</td>\n",
       "      <td>149.9</td>\n",
       "      <td>34</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Rate_NFL  Y/A_NFL   win_pct  AY/A_College  Att_College  \\\n",
       "Player                                                                      \n",
       "A.J. Feeley            66.1      6.2  0.466667           7.6          259   \n",
       "A.J. McCarron          97.1      7.2  0.666667           9.6          978   \n",
       "Aaron Brooks           77.5      6.8  0.422222           8.1          560   \n",
       "Aaron Rodgers         102.7      7.8  0.653179           8.6          665   \n",
       "Akili Smith            54.2      5.0  0.200000           8.8          571   \n",
       "...                     ...      ...       ...           ...          ...   \n",
       "Troy Smith             77.8      8.1  0.500000           9.7          548   \n",
       "Tyler Palko            59.8      5.9  0.250000           8.0         1072   \n",
       "Tyrod Taylor           92.8      7.2  0.523810           9.6          558   \n",
       "Vince Young            76.0      7.2  0.612245           8.0          575   \n",
       "Zach Mettenberger      75.1      6.8  0.000000           9.0          648   \n",
       "\n",
       "                   Cmp_College  G_College  Int_College   Pct  Rate_College  \\\n",
       "Player                                                                       \n",
       "A.J. Feeley                136         10            6  52.5         129.0   \n",
       "A.J. McCarron              656         40           15  67.1         163.3   \n",
       "Aaron Brooks               320         22           16  57.2         139.7   \n",
       "Aaron Rodgers              424         25           13  63.8         150.4   \n",
       "Akili Smith                323         23           15  56.0         147.0   \n",
       "...                        ...        ...          ...   ...           ...   \n",
       "Troy Smith                 352         24           10  64.1         162.3   \n",
       "Tyler Palko                643         35           25  60.4         141.7   \n",
       "Tyrod Taylor               324         27           10  57.8         152.1   \n",
       "Vince Young                360         25           21  62.2         146.2   \n",
       "Zach Mettenberger          399         25           15  61.8         149.9   \n",
       "\n",
       "                   TD_College  Y/A_College  Yds_College  above_nfl_ypa  \\\n",
       "Player                                                                   \n",
       "A.J. Feeley                14          7.5         1951              0   \n",
       "A.J. McCarron              74          8.8         8630              1   \n",
       "Aaron Brooks               32          8.2         4601              0   \n",
       "Aaron Rodgers              43          8.2         5469              1   \n",
       "Akili Smith                45          8.5         5148              0   \n",
       "...                       ...          ...          ...            ...   \n",
       "Troy Smith                 46          8.9         4824              1   \n",
       "Tyler Palko                66          7.8         8330              0   \n",
       "Tyrod Taylor               37          9.1         5054              1   \n",
       "Vince Young                38          8.4         4885              1   \n",
       "Zach Mettenberger          34          8.9         5691              0   \n",
       "\n",
       "                   above_nfl_rate  \n",
       "Player                             \n",
       "A.J. Feeley                     0  \n",
       "A.J. McCarron                   1  \n",
       "Aaron Brooks                    0  \n",
       "Aaron Rodgers                   1  \n",
       "Akili Smith                     0  \n",
       "...                           ...  \n",
       "Troy Smith                      0  \n",
       "Tyler Palko                     0  \n",
       "Tyrod Taylor                    1  \n",
       "Vince Young                     0  \n",
       "Zach Mettenberger               0  \n",
       "\n",
       "[151 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YPA Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Features/Target for YPA. Assign Training and Testing Data.\n",
    "\n",
    "Training Data - Quarterbacks Drafted between 1999-2015. \\\n",
    "Testing Data - Quarterbacks Drafted between 2016-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AY/A_College', 'Att_College','Cmp_College', 'G_College', 'Int_College','Pct','Rate_College','TD_College','Y/A_College','Yds_College']\n",
    "test_qbs = ['Baker Mayfield', 'C.J. Beathard', 'Cody Kessler', 'Dak Prescott', 'Daniel Jones', 'David Blough', 'Deshaun Watson', 'Drew Lock', 'Dwayne Haskins', 'Gardner Minshew', 'Jacoby Brissett', 'Jared Goff', 'Jeff Driskel', 'Josh Allen', 'Josh Rosen', 'Kyle Allen', 'Kyler Murray', 'Lamar Jackson', 'Mason Rudolph', 'Nick Mullens', 'Patrick Mahomes', 'Sam Darnold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.drop(test_qbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:, features]\n",
    "y_train = df_train.loc[:, 'above_nfl_ypa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[test_qbs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, features]\n",
    "y_test = df_test.loc[:, 'above_nfl_ypa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046511627906976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#Most Frequent\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_score_ypa = dummy.score(X_train, y_train)\n",
    "print(dummy.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to have better than 60.5% accuracy in model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.76744186 0.62790698 0.6744186 ]\n",
      "3 fold mean scores 0.689922480620155\n",
      "====================================================================================================\n",
      "5 fold scores [0.73076923 0.65384615 0.69230769 0.73076923 0.68      ]\n",
      "5 fold mean scores 0.6975384615384616\n"
     ]
    }
   ],
   "source": [
    "#all ten features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#3 fold\n",
    "scores3 = cross_val_score(logreg, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3))\n",
    "cv3_logreg_1 = scores3.mean()\n",
    "print('3 fold mean scores ' + str(cv3_logreg_1))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5 = cross_val_score(logreg, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5))\n",
    "cv5_logreg_1 = scores5.mean()\n",
    "print('5 fold mean scores ' + str(cv5_logreg_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly good results, but this is ignoring multicollinearity. Will reduce feature with high Variance Inflation Factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=50):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 'Rate_College' at index: 6\n",
      "dropping 'Y/A_College' at index: 7\n",
      "dropping 'Yds_College' at index: 7\n",
      "dropping 'Att_College' at index: 1\n",
      "dropping 'Pct' at index: 4\n",
      "dropping 'Cmp_College' at index: 1\n",
      "Remaining variables:\n",
      "Index(['AY/A_College', 'G_College', 'Int_College', 'TD_College'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AY/A_College</th>\n",
       "      <th>G_College</th>\n",
       "      <th>Int_College</th>\n",
       "      <th>TD_College</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A.J. Feeley</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>9.6</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>8.1</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>8.6</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Akili Smith</td>\n",
       "      <td>8.8</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Troy Smith</td>\n",
       "      <td>9.7</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyler Palko</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyrod Taylor</td>\n",
       "      <td>9.6</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vince Young</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zach Mettenberger</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AY/A_College  G_College  Int_College  TD_College\n",
       "Player                                                             \n",
       "A.J. Feeley                 7.6         10            6          14\n",
       "A.J. McCarron               9.6         40           15          74\n",
       "Aaron Brooks                8.1         22           16          32\n",
       "Aaron Rodgers               8.6         25           13          43\n",
       "Akili Smith                 8.8         23           15          45\n",
       "...                         ...        ...          ...         ...\n",
       "Troy Smith                  9.7         24           10          46\n",
       "Tyler Palko                 8.0         35           25          66\n",
       "Tyrod Taylor                9.6         27           10          37\n",
       "Vince Young                 8.0         25           21          38\n",
       "Zach Mettenberger           9.0         25           15          34\n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_vif_(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = ['AY/A_College', 'G_College', 'Int_College', 'TD_College']\n",
    "X_train_new = X_train.loc[:, features_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Perform Logistic Regression With Reduced Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.6744186  0.69767442 0.62790698]\n",
      "3 fold mean scores 0.6666666666666666\n",
      "====================================================================================================\n",
      "5 fold scores [0.69230769 0.73076923 0.73076923 0.65384615 0.56      ]\n",
      "5 fold mean scores 0.6735384615384615\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#3 fold\n",
    "scores3_new = cross_val_score(logreg2, X_train_new, y_train, cv=3, scoring = 'accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3_new))\n",
    "cv3_logreg_2 = scores3_new.mean()\n",
    "print('3 fold mean scores ' + str(cv3_logreg_2))\n",
    "\n",
    "print('='*100)\n",
    "\n",
    "#5 fold\n",
    "scores5_new = cross_val_score(logreg, X_train_new, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5_new))\n",
    "cv5_logreg_2 = scores5_new.mean()\n",
    "print('5 fold mean scores ' + str(cv5_logreg_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent results. Will now fit all of training data and score testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Test Data\n",
    "X_test_new = X_test.loc[:, features_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2.fit(X_train_new, y_train)\n",
    "logreg2_score = logreg2.score(X_test_new, y_test)\n",
    "logreg2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression performs very poorly when predicting test data. Will see if parameter tuning can improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_logreg(X, y):\n",
    "    param_grid = {'C' : [0.001, 0.1, 1, 10, 100]}\n",
    "    \n",
    "    logreg = LogisticRegression(solver='liblinear')\n",
    "    logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "    \n",
    "    logreg_cv.fit(X, y)\n",
    "    \n",
    "    print(logreg_cv.best_params_)\n",
    "    print(logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.6812307692307693\n"
     ]
    }
   ],
   "source": [
    "grid_search_logreg(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logreg with best C\n",
    "logreg = LogisticRegression(solver='liblinear', C =10)\n",
    "\n",
    "logreg.fit(X_train_new, y_train)\n",
    "logreg3_test_score = logreg.score(X_test_new, y_test)\n",
    "logreg3_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same score. Will move on to trying DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.51162791 0.69767442 0.60465116]\n",
      "3 fold mean scores 0.6046511627906976\n",
      "====================================================================================================\n",
      "5 fold scores [0.53846154 0.46153846 0.46153846 0.53846154 0.68      ]\n",
      "5 fold mean scores 0.536\n"
     ]
    }
   ],
   "source": [
    "#out of the box\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#3 fold\n",
    "scores3 = cross_val_score(clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3))\n",
    "cv3_dt_1 = scores3.mean()\n",
    "print('3 fold mean scores ' + str(cv3_dt_1))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5 = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5))\n",
    "cv5_dt_1 = scores5.mean()\n",
    "print('5 fold mean scores ' + str(cv5_dt_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.58139535 0.69767442 0.62790698]\n",
      "3 fold mean scores 0.6356589147286822\n",
      "====================================================================================================\n",
      "5 fold scores [0.65384615 0.69230769 0.73076923 0.53846154 0.6       ]\n",
      "5 fold mean scores 0.6430769230769231\n"
     ]
    }
   ],
   "source": [
    "#simple tuning\n",
    "clf_tune = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "\n",
    "#3 fold\n",
    "scores3 = cross_val_score(clf_tune, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3))\n",
    "cv3_dt_2 = scores3.mean()\n",
    "print('3 fold mean scores ' + str(scores3.mean()))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5 = cross_val_score(clf_tune, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print('5 fold scores ' + str(scores5))\n",
    "cv5_dt_2 = scores5.mean()\n",
    "print('5 fold mean scores ' + str(scores5.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores improved considerably. Will now get score on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909090909090909"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tune.fit(X_train, y_train)\n",
    "dt_test_score = clf_tune.score(X_test, y_test)\n",
    "dt_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for YPA\n",
    "\n",
    "Modeling the YPA using Logistic Regression and Decision Tree models did not provide significantly accurate results. Will try out using Passer Rating as target variable to see if results improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passer Rating Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Features and Target for Passer Rating. Assign Training and Testing Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "X_train_rate = df_train.loc[:, features]\n",
    "y_train_rate = df_train.loc[:, 'above_nfl_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "X_test_rate = df_test.loc[:, features]\n",
    "y_test_rate = df_test.loc[:, 'above_nfl_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#Most Frequent\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train_rate, y_train_rate)\n",
    "dummy_score_rate = dummy.score(X_train_rate, y_train_rate)\n",
    "print(dummy_score_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression w/ Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.60465116 0.65116279 0.65116279]\n",
      "3 fold mean scores 0.6356589147286822\n",
      "====================================================================================================\n",
      "5 fold scores [0.57692308 0.61538462 0.61538462 0.65384615 0.64      ]\n",
      "5 fold mean scores 0.6203076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#3 fold\n",
    "scores3 = cross_val_score(logreg, X_train_rate, y_train_rate, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3))\n",
    "cv3_logreg_1_rate = scores3.mean()\n",
    "print('3 fold mean scores ' + str(scores3.mean()))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5 = cross_val_score(logreg, X_train_rate, y_train_rate, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5))\n",
    "cv5_logreg_1_rate = scores5.mean()\n",
    "print('5 fold mean scores ' + str(scores5.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to account for Multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 'Rate_College' at index: 6\n",
      "dropping 'Y/A_College' at index: 7\n",
      "dropping 'Yds_College' at index: 7\n",
      "dropping 'Att_College' at index: 1\n",
      "dropping 'Pct' at index: 4\n",
      "dropping 'Cmp_College' at index: 1\n",
      "Remaining variables:\n",
      "Index(['AY/A_College', 'G_College', 'Int_College', 'TD_College'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AY/A_College</th>\n",
       "      <th>G_College</th>\n",
       "      <th>Int_College</th>\n",
       "      <th>TD_College</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A.J. Feeley</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>9.6</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>8.1</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>8.6</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Akili Smith</td>\n",
       "      <td>8.8</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Troy Smith</td>\n",
       "      <td>9.7</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyler Palko</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tyrod Taylor</td>\n",
       "      <td>9.6</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vince Young</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zach Mettenberger</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AY/A_College  G_College  Int_College  TD_College\n",
       "Player                                                             \n",
       "A.J. Feeley                 7.6         10            6          14\n",
       "A.J. McCarron               9.6         40           15          74\n",
       "Aaron Brooks                8.1         22           16          32\n",
       "Aaron Rodgers               8.6         25           13          43\n",
       "Akili Smith                 8.8         23           15          45\n",
       "...                         ...        ...          ...         ...\n",
       "Troy Smith                  9.7         24           10          46\n",
       "Tyler Palko                 8.0         35           25          66\n",
       "Tyrod Taylor                9.6         27           10          37\n",
       "Vince Young                 8.0         25           21          38\n",
       "Zach Mettenberger           9.0         25           15          34\n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_vif_(X_train_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rate_new = X_train_rate.loc[:, features_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression After Reducing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.72093023 0.65116279 0.65116279]\n",
      "3 fold mean scores 0.6744186046511628\n",
      "====================================================================================================\n",
      "5 fold scores [0.73076923 0.73076923 0.61538462 0.69230769 0.64      ]\n",
      "5 fold mean scores 0.6818461538461539\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#3 fold\n",
    "scores3_new = cross_val_score(logreg2, X_train_rate_new, y_train_rate, cv=3, scoring = 'accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3_new))\n",
    "cv3_logreg_2_rate = scores3_new.mean()\n",
    "print('3 fold mean scores ' + str(scores3_new.mean()))\n",
    "\n",
    "print('='*100)\n",
    "\n",
    "#5 fold\n",
    "scores5_new = cross_val_score(logreg, X_train_rate_new, y_train_rate, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5_new))\n",
    "cv5_logreg_2_rate = scores5_new.mean()\n",
    "print('5 fold mean scores ' + str(scores5_new.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results after reducing features. Will now see if parameter tuning improves score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.6898461538461539\n"
     ]
    }
   ],
   "source": [
    "grid_search_logreg(X_train_rate_new, y_train_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new test data\n",
    "X_test_rate_new = X_test_rate.loc[:, features_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model with new C and score testing data\n",
    "logreg = LogisticRegression(solver='liblinear', C=10)\n",
    "logreg.fit(X_train_rate_new, y_train_rate)\n",
    "logreg_test_score_rate = logreg.score(X_test_rate_new, y_test_rate)\n",
    "logreg_test_score_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score worse than DummyClassifier as with Logistic Regression with YPA as target. Now try Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.55813953 0.58139535 0.51162791]\n",
      "3 fold mean scores 0.5503875968992248\n",
      "====================================================================================================\n",
      "5 fold scores [0.42307692 0.53846154 0.5        0.5        0.48      ]\n",
      "5 fold mean scores 0.4883076923076922\n"
     ]
    }
   ],
   "source": [
    "#out of the box\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#3 fold\n",
    "scores3_new = cross_val_score(clf, X_train_rate, y_train_rate, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3_new))\n",
    "cv3_dt_1_rate = scores3_new.mean()\n",
    "print('3 fold mean scores ' + str(scores3_new.mean()))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5_new = cross_val_score(clf, X_train_rate, y_train_rate, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5_new))\n",
    "cv5_dt_1_rate = scores5_new.mean()\n",
    "print('5 fold mean scores ' + str(scores5_new.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the box had poor results. Will try out some parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold scores [0.62790698 0.60465116 0.60465116]\n",
      "3 fold mean scores 0.6124031007751938\n",
      "====================================================================================================\n",
      "5 fold scores [0.65384615 0.61538462 0.53846154 0.69230769 0.56      ]\n",
      "5 fold mean scores 0.612\n"
     ]
    }
   ],
   "source": [
    "#some tuning\n",
    "clf_tune = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "\n",
    "#3 fold\n",
    "scores3_new = cross_val_score(clf_tune, X_train_rate, y_train_rate, cv=3, scoring='accuracy')\n",
    "\n",
    "print('3 fold scores ' + str(scores3_new))\n",
    "cv3_dt_2_rate = scores3_new.mean()\n",
    "print('3 fold mean scores ' + str(scores3_new.mean()))\n",
    "\n",
    "print('=' * 100)\n",
    "\n",
    "#5 fold\n",
    "scores5_new = cross_val_score(clf_tune, X_train_rate, y_train_rate, cv=5, scoring='accuracy')\n",
    "\n",
    "print('5 fold scores ' + str(scores5_new))\n",
    "cv5_dt_2_rate = scores5_new.mean()\n",
    "print('5 fold mean scores ' + str(scores5_new.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better scores. Will now fit with training data and score testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "clf_tune.fit(X_train_rate, y_train_rate)\n",
    "\n",
    "dt_test_score_rate = clf_tune.score(X_test_rate, y_test_rate)\n",
    "print(dt_test_score_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score so far. Will explore further to see if we can reproduce and maybe improve by running several iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_tune.predict(X_test_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1]\n",
      " [ 4 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test_rate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74         8\n",
      "           1       0.91      0.71      0.80        14\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.77      0.79      0.77        22\n",
      "weighted avg       0.81      0.77      0.78        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_rate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will rerun model by splitting training data several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists of values for each quarterback\n",
    "predictions = [[] for i in range(len(X_test_rate.index))]\n",
    "scores = []\n",
    "starting_seed = 100\n",
    "num_splits = 100\n",
    "count = 1\n",
    "\n",
    "# Repeat this process for different training/test splits\n",
    "for i in range(starting_seed, starting_seed+num_splits):\n",
    "    \n",
    "    count = count+1\n",
    "    \n",
    "    # Split into training-test\n",
    "    X_train, X_t, y_train, y_t = train_test_split(X_train_rate, y_train_rate, test_size=0.10, random_state=i+1, stratify=y_train_rate)\n",
    "    \n",
    "    \n",
    "    # Fit random forest\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "    \n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on recent quarterbacks\n",
    "    y_predict = dt.predict(X_test_rate)\n",
    "    scores.append(dt.score(X_test_rate, y_test_rate))\n",
    "    # Add result to list\n",
    "    for i in range(0, len(list(y_predict))):\n",
    "        predictions[i].append(y_predict[i])\n",
    "    \n",
    "        \n",
    "qb_results = {}\n",
    "\n",
    "for i in range(len(X_test_rate)):\n",
    "    qb_results[X_test_rate.index[i]] = predictions[i]\n",
    "\n",
    "# Collect and display the means and standard deviations of each quarterback's predictions\n",
    "means = []\n",
    "\n",
    "for i in qb_results:\n",
    "    means.append(round(np.mean(qb_results[i]),2))\n",
    "    \n",
    "test_results = pd.DataFrame({'Player':X_test_rate.index ,'mean':means})[['Player', 'mean']]\n",
    "\n",
    "test_results['result'] = [1 if test_result > 0.5 else 0 for test_result in test_results['mean']]\n",
    "\n",
    "test_results['actual'] = y_test_rate.values\n",
    "\n",
    "test_results['Rate_NFL'] = df_test['Rate_NFL'].values\n",
    "test_results = test_results.sort_values(by='Rate_NFL', ascending= False)\n",
    "test_results['true / false'] = test_results.result == test_results.actual\n",
    "test_results = test_results.set_index('Player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n",
      "0.36363636363636365\n",
      "0.6363636363636364\n",
      "0.7727272727272727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statistics import mode\n",
    "plt.plot(scores,'bo' )\n",
    "print(np.max(scores)) \n",
    "print(np.min(scores))\n",
    "print(np.median(scores))\n",
    "print(mode(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>result</th>\n",
       "      <th>actual</th>\n",
       "      <th>Rate_NFL</th>\n",
       "      <th>true / false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Patrick Mahomes</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>109.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Deshaun Watson</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lamar Jackson</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dak Prescott</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gardner Minshew</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Nick Mullens</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Drew Lock</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jared Goff</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Daniel Jones</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kyler Murray</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Baker Mayfield</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jacoby Brissett</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cody Kessler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mason Rudolph</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sam Darnold</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kyle Allen</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jeff Driskel</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dwayne Haskins</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C.J. Beathard</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>David Blough</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Josh Rosen</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean  result  actual  Rate_NFL  true / false\n",
       "Player                                                       \n",
       "Patrick Mahomes  0.25       0       1     109.6         False\n",
       "Deshaun Watson   0.56       1       1     101.4          True\n",
       "Lamar Jackson    0.57       1       1      98.9          True\n",
       "Dak Prescott     0.67       1       1      97.0          True\n",
       "Gardner Minshew  0.14       0       1      91.2         False\n",
       "Nick Mullens     0.62       1       1      90.8          True\n",
       "Drew Lock        0.61       1       1      89.7          True\n",
       "Jared Goff       0.65       1       1      87.9          True\n",
       "Daniel Jones     0.13       0       1      87.7         False\n",
       "Kyler Murray     0.53       1       1      87.4          True\n",
       "Baker Mayfield   0.72       1       1      86.2          True\n",
       "Jacoby Brissett  0.00       0       1      84.8         False\n",
       "Cody Kessler     0.80       1       1      84.8          True\n",
       "Mason Rudolph    0.80       1       1      82.0          True\n",
       "Sam Darnold      0.29       0       0      80.9          True\n",
       "Kyle Allen       0.00       0       0      80.0          True\n",
       "Jeff Driskel     0.18       0       0      78.8          True\n",
       "Josh Allen       0.00       0       0      76.6          True\n",
       "Dwayne Haskins   0.33       0       0      76.1          True\n",
       "C.J. Beathard    0.16       0       0      75.5          True\n",
       "David Blough     0.14       0       0      64.0          True\n",
       "Josh Rosen       0.01       0       0      59.4          True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_100_iterations = test_results['true / false'].value_counts()[1] / len(test_results)\n",
    "model_score_100_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c19e46910>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(test_results['actual'], test_results['result']))\n",
    "labels = np.array([['TN : ' + str(cm[0][0]), 'FP: ' + str(cm[1][0])], ['FN: ' + str(cm[0][1]), 'TP: ' + str(cm[1][1])]])\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14\n",
       "0     8\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cmp_College     0.410863\n",
       "Pct             0.347966\n",
       "Y/A_College     0.241171\n",
       "Yds_College     0.000000\n",
       "TD_College      0.000000\n",
       "Rate_College    0.000000\n",
       "Int_College     0.000000\n",
       "G_College       0.000000\n",
       "Att_College     0.000000\n",
       "AY/A_College    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(dt.feature_importances_, index=X_test_rate.columns).sort_values(ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yards Per Attempt Modeling\n",
      "YPA DummyClassifier Score: 0.6046511627906976\n",
      "YPA Logistic Regression 3-Fold Cross-Validation Score, all features: 0.689922480620155\n",
      "YPA Logistic Regression 5-Fold Cross-Validation Score, all features: 0.6975384615384616\n",
      "====================================================================================================\n",
      "YPA Logistic Regression 3-Fold Cross-Validation Score, Reduced Features: 0.6666666666666666\n",
      "YPA Logistic Regression 5-Fold Cross-Validation Score, Reduced Features: 0.6735384615384615\n",
      "====================================================================================================\n",
      "YPA Logistic Regression with Parameter Tuning Test Score: 0.5\n",
      "====================================================================================================\n",
      "YPA DecisionTree 3-Fold Cross-Validation Score: 0.6046511627906976\n",
      "YPA DecisionTree 5-Fold Cross-Validation Score: 0.536\n",
      "YPA DecisionTree with Parameter Tuning Test Score: 0.5909090909090909\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Passer Rating Modeling\n",
      "Passer Rating DummyClassifier Score: 0.6666666666666666\n",
      "Passer Rating Logistic Regression 3-Fold Cross-Validation Score, all features: 0.6356589147286822\n",
      "Passer Rating Logistic Regression 5-Fold Cross-Validation Score, all features: 0.6203076923076923\n",
      "====================================================================================================\n",
      "Passer Rating Logistic Regression 3-Fold Cross-Validation Score, Reduced Features: 0.6744186046511628\n",
      "Passer Rating Logistic Regression 5-Fold Cross-Validation Score, Reduced Features: 0.6818461538461539\n",
      "====================================================================================================\n",
      "Passer Rating Logistic Regression with Parameter Tuning Test Score: 0.5\n",
      "====================================================================================================\n",
      "Passer Rating DecisionTree 3-Fold Cross-Validation Score: 0.5503875968992248\n",
      "Passer Rating DecisionTree 5-Fold Cross-Validation Score: 0.4883076923076922\n",
      "====================================================================================================\n",
      "Passer Rating DecisionTree 3-Fold Cross-Validation Score, Parameter Tuning: 0.6124031007751938\n",
      "Passer Rating DecisionTree 5-Fold Cross-Validation Score, Parameter Tuning: 0.612\n",
      "Passer Rating DecisionTree with Parameter Tuning Test Score: 0.7727272727272727\n",
      "====================================================================================================\n",
      "100 Iterations of Model: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print('Yards Per Attempt Modeling')\n",
    "print('YPA DummyClassifier Score: ' + str(dummy_score_ypa))\n",
    "print('YPA Logistic Regression 3-Fold Cross-Validation Score, all features: ' + str(cv3_logreg_1))\n",
    "print('YPA Logistic Regression 5-Fold Cross-Validation Score, all features: ' + str(cv5_logreg_1))\n",
    "print('=' * 100)\n",
    "print('YPA Logistic Regression 3-Fold Cross-Validation Score, Reduced Features: ' + str(cv3_logreg_2))\n",
    "print('YPA Logistic Regression 5-Fold Cross-Validation Score, Reduced Features: ' + str(cv5_logreg_2))\n",
    "print('=' * 100)\n",
    "print('YPA Logistic Regression with Parameter Tuning Test Score: ' + str(logreg3_test_score))\n",
    "print('=' * 100)\n",
    "print('YPA DecisionTree 3-Fold Cross-Validation Score: ' + str(cv3_dt_1))\n",
    "print('YPA DecisionTree 5-Fold Cross-Validation Score: ' + str(cv5_dt_1))\n",
    "print('YPA DecisionTree with Parameter Tuning Test Score: ' + str(dt_test_score))\n",
    "print('='*100)\n",
    "print('='*100)\n",
    "print('Passer Rating Modeling')\n",
    "print('Passer Rating DummyClassifier Score: ' + str(dummy_score_rate))\n",
    "print('Passer Rating Logistic Regression 3-Fold Cross-Validation Score, all features: ' + str(cv3_logreg_1_rate))\n",
    "print('Passer Rating Logistic Regression 5-Fold Cross-Validation Score, all features: ' + str(cv5_logreg_1_rate))\n",
    "print('=' * 100)\n",
    "print('Passer Rating Logistic Regression 3-Fold Cross-Validation Score, Reduced Features: ' + str(cv3_logreg_2_rate))\n",
    "print('Passer Rating Logistic Regression 5-Fold Cross-Validation Score, Reduced Features: ' + str(cv5_logreg_2_rate))\n",
    "print('=' * 100)\n",
    "print('Passer Rating Logistic Regression with Parameter Tuning Test Score: ' + str(logreg_test_score_rate))\n",
    "print('=' * 100)\n",
    "print('Passer Rating DecisionTree 3-Fold Cross-Validation Score: ' + str(cv3_dt_1_rate))\n",
    "print('Passer Rating DecisionTree 5-Fold Cross-Validation Score: ' + str(cv5_dt_1_rate))\n",
    "print('=' *100)\n",
    "print('Passer Rating DecisionTree 3-Fold Cross-Validation Score, Parameter Tuning: ' + str(cv3_dt_2_rate))\n",
    "print('Passer Rating DecisionTree 5-Fold Cross-Validation Score, Parameter Tuning: ' + str(cv5_dt_2_rate))\n",
    "print('Passer Rating DecisionTree with Parameter Tuning Test Score: ' + str(dt_test_score_rate))\n",
    "print('=' * 100)\n",
    "print('100 Iterations of Model: ' + str(model_score_100_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
